# ğŸ­ AnÃ¡lisis de Emociones Faciales en Tiempo Real

![React](https://img.shields.io/badge/React-20232A?style=for-the-badge&logo=react&logoColor=61DAFB)
![Node.js](https://img.shields.io/badge/Node.js-339933?style=for-the-badge&logo=nodedotjs&logoColor=white)
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Flask](https://img.shields.io/badge/Flask-000000?style=for-the-badge&logo=flask&logoColor=white)
![DeepFace](https://img.shields.io/badge/DeepFace-4A4A4A?style=for-the-badge&logo=tensorflow&logoColor=FF6F00)

Este proyecto es una aplicaciÃ³n web full-stack diseÃ±ada para analizar emociones faciales a partir de imÃ¡genes estÃ¡ticas o de una transmisiÃ³n de video en tiempo real desde la webcam del usuario.

---

Dado que la arquitectura de este proyecto es compleja para un despliegue pÃºblico (Las librerÃ­as de deep-face son extremadamente grandes), he publicado todo el cÃ³digo para que podÃ¡is instalarlo en vuestro sistema y probarlo


#### AnÃ¡lisis de Imagen Subida

![4](https://github.com/user-attachments/assets/c9bcb02c-097b-47c9-bbed-a1b53505efef)


#### AnÃ¡lisis en Tiempo Real con Webcam

![2](https://github.com/user-attachments/assets/8f023de9-c516-4ca7-b31a-e317390c87c7)

---

### âœ¨ CaracterÃ­sticas Principales

* **Sistema de AutenticaciÃ³n Completo**: Registro e inicio de sesiÃ³n de usuarios con tokens JWT para proteger las rutas.
* **AnÃ¡lisis de ImÃ¡genes**: Sube un archivo de imagen (JPG, PNG) y la aplicaciÃ³n detectarÃ¡ la emociÃ³n facial predominante y un ranking de las mÃ¡s probables.
* **AnÃ¡lisis en Tiempo Real**: Activa la webcam para obtener un anÃ¡lisis continuo de tus expresiones faciales, con una superposiciÃ³n que muestra la emociÃ³n detectada en cada momento.
* **Interfaz Reactiva**: Construido con React para una experiencia de usuario fluida y dinÃ¡mica.

---

### ğŸ—ï¸ Arquitectura del Proyecto

Este proyecto sigue una arquitectura de microservicios, compuesta por tres partes independientes que se comunican entre sÃ­:

1.  **Frontend (Este Repositorio)**: Una aplicaciÃ³n de una sola pÃ¡gina (SPA) construida con **React** que gestiona la interfaz de usuario y la interacciÃ³n.
2.  **Backend de AutenticaciÃ³n**: Un servidor en **Node.js** con **Express** que maneja el registro, login y la validaciÃ³n de usuarios mediante JWT.
    * **[ğŸ”— Ver Repositorio del Backend de AutenticaciÃ³n](https://github.com/JulioMontesinos/Back_Platform_Recognition_Face)**
3.  **Backend de IA (AnÃ¡lisis Facial)**: Un servidor en **Python** con **Flask** que utiliza la librerÃ­a **DeepFace** y **OpenCV** para realizar todo el procesamiento y anÃ¡lisis de las imÃ¡genes.
    * **[ğŸ”— Ver Repositorio del Backend de IA](https://github.com/JulioMontesinos/facial_emotion)**

## AnÃ¡lisis de la Arquitectura y Flujos de Datos

Frontend (Cliente): Una aplicaciÃ³n React que se ejecuta en el navegador del usuario. Es responsable de toda la interfaz y la gestiÃ³n del estado del lado del cliente (como el token de autenticaciÃ³n).

    Backend de AutenticaciÃ³n (Servidor Node.js): Una API REST construida con Express que gestiona exclusivamente a los usuarios. Su lÃ³gica principal incluye:

        Validar credenciales contra la base de datos diseÃ±ado para MongoDB.

        Hashear contraseÃ±as con bcrypt.

        Crear y validar JSON Web Tokens (JWT) para las sesiones.

    Backend de IA (Servidor Python): Un servidor Flask dedicado a la computaciÃ³n pesada. Su lÃ³gica principal incluye:

        Recibir imÃ¡genes y frames de video.

        Usar OpenCV para el pre-procesamiento de imÃ¡genes (decodificar, cambiar color, redimensionar).

        Utilizar la librerÃ­a DeepFace (con TensorFlow por debajo) para ejecutar el modelo de anÃ¡lisis de emociones.

        Servir un stream de video en vivo.

Flujos de Datos Detallados:

1. Flujo de AutenticaciÃ³n:

    Paso 1: El usuario introduce su email y contraseÃ±a en el formulario de React.

    Paso 2: El frontend envÃ­a una peticiÃ³n POST a /api/auth/login en el servidor Node.js.

    Paso 3: El servidor Node.js busca al usuario por email y compara la contraseÃ±a hasheada usando bcrypt.

    Paso 4: Si las credenciales son vÃ¡lidas, genera un JWT y lo devuelve al frontend.

    Paso 5: El frontend de React guarda el JWT en localStorage para autenticar peticiones futuras a rutas protegidas.

2. Flujo de AnÃ¡lisis de Emociones (Imagen y Video):

    Paso 1: Desde una ruta protegida, el usuario sube una imagen o activa la webcam.

    Paso 2 (Imagen): El frontend envÃ­a la imagen en un FormData a la ruta /analyze-image del servidor Python/Flask.

    Paso 2 (Webcam): El frontend hace dos cosas en paralelo:

        Establece una conexiÃ³n GET a /video_feed para recibir el stream de video.

        PeriÃ³dicamente, captura un frame y lo envÃ­a vÃ­a POST a /analyze-image.

    Paso 3: El servidor Flask recibe la imagen, OpenCV la pre-procesa, y DeepFace la analiza.

    Paso 4: El servidor Flask devuelve un objeto JSON con la emociÃ³n dominante, el porcentaje de confianza y un ranking de emociones.

    Paso 5: El frontend de React recibe este JSON y actualiza la interfaz para mostrar los resultados al usuario.

### ğŸ› ï¸ TecnologÃ­as Utilizadas

* **Frontend**: React, Vite, Axios, JWT-Decode, React Router.
* **Backend (AutenticaciÃ³n)**: Node.js, Express, bcryptjs, JSON Web Token (JWT), CORS.
* **Backend (IA)**: Python, Flask, DeepFace, TensorFlow, OpenCV, NumPy.

---

### ğŸš€ CÃ³mo Ejecutar este Proyecto Localmente

Para poner en marcha este proyecto, necesitarÃ¡s tener los tres servidores funcionando simultÃ¡neamente.

#### **Pre-requisitos**
* Node.js (v18 o superior)
* Python (v3.9 o superior)
* Git

#### **1. Clonar los Repositorios**
Abre tu terminal y clona los tres repositorios en una misma carpeta.

```bash
# Clona este repositorio (Frontend)
git clone https://github.com/JulioMontesinos/Front_Platform_Recognition_Face.git

# Clona el Backend de AutenticaciÃ³n
git clone https://github.com/JulioMontesinos/Back_Platform_Recognition_Face.git

# Clona el Backend de IA
git clone https://github.com/JulioMontesinos/facial_emotion.git
```

#### **2. Configurar y Lanzar el Backend de AutenticaciÃ³n (Node.js)**

# Navega a la carpeta del backend de auth
cd Back_Platform_Recognition_Face

# Instala las dependencias
npm install

# El fichero .env del backend serÃ­a algo parecido a esto:

![env](https://github.com/user-attachments/assets/7f6123f2-3cf3-4c9c-beee-dcae33fa34b6)

# El fichero .env del front serÃ­a algo parecido a esto:

VITE_BACK_URL=http://localhost:5000

# Inicia el servidor
npm run dev

> ğŸ•’ *El servidor de autenticaciÃ³n deberÃ­a estar corriendo en `http://localhost:5000`.*

#### **3. Configurar y Lanzar el Backend de IA (Python)**

# Abre una NUEVA terminal y navega a la carpeta del backend de IA
cd facial_emotion

# Crea y activa un entorno virtual
python -m venv env
source env/bin/activate  # En Windows: env\Scripts\activate

# Instala las dependencias
pip install -r requirements.txt

# Inicia el servidor Flask
python server.py

    ğŸ•’ El servidor de IA puede tardar un poco en arrancar la primera vez mientras carga el modelo. DeberÃ­a estar corriendo en http://localhost:5001.

Salida Esperada en la Terminal del Servidor de IA

Una vez que inicies el anÃ¡lisis con la webcam, verÃ¡s en esta terminal un registro de la actividad en tiempo real. Esto confirma que el frontend se estÃ¡ comunicando con el backend y que la librerÃ­a DeepFace estÃ¡ procesando las imÃ¡genes correctamente.

![image](https://github.com/user-attachments/assets/946d0f55-9fe5-4f19-b163-17f8f6b0cc1a)



#### **4. Configurar y Lanzar el Frontend (React)**

# Abre una TERCERA terminal y navega a la carpeta del frontend
cd Front_Platform_Recognition_Face

# Instala las dependencias
npm install

# Inicia la aplicaciÃ³n de desarrollo
npm run dev

> ğŸš€ Â¡Listo! Abre tu navegador y ve a `http://localhost:5173` para usar la aplicaciÃ³n.
